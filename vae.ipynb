{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyP7yeRrq14WGLwlgiuVLW8d"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "35FH1sriN2n7",
        "outputId": "08babdfb-8820-4458-cf1f-902d3ee08e06"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "torch.manual_seed(42)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "torch.set_default_dtype(torch.float32)\n",
        "print(f\"Using device: {device}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Lambda(lambda x: x.view(-1)),  # flatten 32x32x3 to 3072\n",
        "    transforms.Lambda(lambda x: x.to(torch.float32))  # ensure cons dtype\n",
        "])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(\n",
        "    root='./data',\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=transform\n",
        ")\n",
        "\n",
        "batch_size = 128\n",
        "trainloader = DataLoader(\n",
        "    trainset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        "    num_workers=2,\n",
        "    pin_memory=True,\n",
        "    persistent_workers=True  # workers alive between epochs\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1OF9zgGlQ61_",
        "outputId": "bb670e23-4851-4497-cd5a-9bc9fe39b3ea"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170M/170M [00:05<00:00, 30.8MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class VAE(nn.Module):\n",
        "    def __init__(self, input_dim=3072, hidden_dim=400, latent_dim=20):\n",
        "        super(VAE, self).__init__()\n",
        "\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Linear(input_dim, hidden_dim),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "        self.fc_mu = nn.Linear(hidden_dim, latent_dim) # mean\n",
        "        self.fc_var = nn.Linear(hidden_dim, latent_dim) # std\n",
        "\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(latent_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim, input_dim),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def encode(self, x):\n",
        "        h = self.encoder(x)\n",
        "        return self.fc_mu(h), self.fc_var(h)\n",
        "\n",
        "    def reparameterize(self, mu, log_var):\n",
        "        std = torch.exp(0.5 * log_var)\n",
        "        eps = torch.randn_like(std)\n",
        "        return mu + eps * std\n",
        "\n",
        "    def forward(self, x):\n",
        "        mu, log_var = self.encode(x)\n",
        "        z = self.reparameterize(mu, log_var)\n",
        "        return self.decoder(z), mu, log_var"
      ],
      "metadata": {
        "id": "Ea2Z-vutRNs2"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = VAE().to(device)\n",
        "test_batch, _ = next(iter(trainloader))\n",
        "test_batch = test_batch.to(device)\n",
        "recon_batch, mu, log_var = model(test_batch)\n",
        "\n",
        "print(f\"input shape: {test_batch.shape}\")\n",
        "print(f\"reconstructed shape: {recon_batch.shape}\")\n",
        "print(f\"mu shape: {mu.shape}\")\n",
        "print(f\"log_var shape: {log_var.shape}\")"
      ],
      "metadata": {
        "id": "xISLIWjqTndD",
        "outputId": "cc1cb7a6-1de7-45b9-96a8-29528edc5e72",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input shape: torch.Size([128, 3072])\n",
            "reconstructed shape: torch.Size([128, 3072])\n",
            "mu shape: torch.Size([128, 20])\n",
            "log_var shape: torch.Size([128, 20])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def loss_function(recon_x, x, mu, log_var):\n",
        "    # reconstruction loss (BCE)\n",
        "    BCE = F.binary_cross_entropy(recon_x, x, reduction='sum')\n",
        "\n",
        "    # kl divergence loss = 0.5 * sum(1 + log(sigma^2) - mu^2 - sigma^2)\n",
        "    KLD = -0.5 * torch.sum(1 + log_var - mu.pow(2) - log_var.exp())\n",
        "\n",
        "    return BCE + KLD"
      ],
      "metadata": {
        "id": "J8jn81nJTyBC"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, trainloader, epochs=30):\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
        "\n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "        total_loss = 0\n",
        "        for batch_idx, (data, _) in enumerate(tqdm(trainloader)):\n",
        "            data = data.to(device)\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            recon_batch, mu, log_var = model(data)\n",
        "\n",
        "            loss = loss_function(recon_batch, data, mu, log_var)\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        avg_loss = total_loss / len(trainloader.dataset)\n",
        "        print(f\"epoch [{epoch+1}/{epochs}] avg Loss: {avg_loss:.4f}\")"
      ],
      "metadata": {
        "id": "5d3_uHzjUHbb"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_reconstruction(model, data):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "\n",
        "        recon_batch, _, _ = model(data.to(device))\n",
        "\n",
        "        # plot original and reconstruction\n",
        "        plt.figure(figsize=(12, 6))\n",
        "\n",
        "        for i in range(8):\n",
        "            plt.subplot(2, 8, i + 1)\n",
        "            plt.imshow(data[i].view(3, 32, 32).permute(1, 2, 0).cpu())\n",
        "            plt.axis('off')\n",
        "            if i == 0:\n",
        "                plt.title(\"original\")\n",
        "\n",
        "        for i in range(8):\n",
        "            plt.subplot(2, 8, i + 9)\n",
        "            plt.imshow(recon_batch[i].view(3, 32, 32).permute(1, 2, 0).cpu())\n",
        "            plt.axis('off')\n",
        "            if i == 0:\n",
        "                plt.title(\"reconstruction\")\n",
        "\n",
        "        plt.tight_layout()"
      ],
      "metadata": {
        "id": "RFRwhJgMUQPF"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = VAE().to(device)\n",
        "train(model, trainloader, epochs=30)\n",
        "\n",
        "test_batch, _ = next(iter(trainloader))\n",
        "plot_reconstruction(model, test_batch)"
      ],
      "metadata": {
        "id": "rieI_vI4UoJI",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_images(model, num_images=8):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "\n",
        "        z = torch.randn(num_images, 20).to(device)\n",
        "        sample = model.decoder(z)\n",
        "\n",
        "        plt.figure(figsize=(12, 3))\n",
        "        for i in range(num_images):\n",
        "            plt.subplot(1, num_images, i + 1)\n",
        "            plt.imshow(sample[i].view(3, 32, 32).permute(1, 2, 0).cpu())\n",
        "            plt.axis('off')\n",
        "        plt.tight_layout()\n",
        "\n",
        "generate_images(model)"
      ],
      "metadata": {
        "id": "19vzIzbHYdbO",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}